{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbb822e-82d1-4d4f-923c-66eb94e0ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import col, unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c465a4b2-b7bb-4ee3-8146-b56052cd14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/04 20:22:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0fcdbb-b187-487d-8189-41aa9d779f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9c3487b-fd7d-48b6-83d0-f718c493f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .parquet('yellow_tripdata_2024-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7e6e07-997e-4a21-92f4-69c1381ffb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2658b296-5efc-40ea-9033-bb4906ca3a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write.parquet('pq/', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87fb79b0-bea4-4725-bbe8-d9b799ce78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ae2d67-55f4-40b3-93e6-c9997156bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_parquet_size(directory):\n",
    "    parquet_files = [f for f in os.listdir(directory) if f.endswith(\".parquet\")]\n",
    "    \n",
    "    if not parquet_files:\n",
    "        return 0  \n",
    "    \n",
    "    total_size = sum(os.path.getsize(os.path.join(directory, f)) for f in parquet_files)\n",
    "    average_size = total_size / len(parquet_files)\n",
    "    \n",
    "    return average_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3dc218-8b01-4dd9-88a1-5aae12048552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average size of Parquet files: 23.04 MB\n"
     ]
    }
   ],
   "source": [
    "directory = \"pq/\"\n",
    "average_size = get_average_parquet_size(directory)\n",
    "print(f\"Average size of Parquet files: {average_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "781b29d3-ff80-4ed8-aeae-ee35a574ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = df \\\n",
    "    .withColumn(\"pickup_date\", F.to_date(df.tpep_pickup_datetime)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24672238-2343-42bb-b51e-b235efc74868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128893"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = df_date\\\n",
    "    .filter(df_date.pickup_date == \"2024-10-15\") \\\n",
    "    .count()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d6f60e7-6eea-4d19-a3b3-1008d98af4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b237144-6bac-423d-b0f8-3563a5bede01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       trip_duration|\n",
      "+--------------------+\n",
      "|  0.5202777777777777|\n",
      "|0.050555555555555555|\n",
      "| 0.19777777777777777|\n",
      "|  0.8927777777777778|\n",
      "| 0.09944444444444445|\n",
      "|  0.3713888888888889|\n",
      "| 0.11777777777777777|\n",
      "| 0.20666666666666667|\n",
      "|  0.6480555555555556|\n",
      "|  0.2452777777777778|\n",
      "|  0.2747222222222222|\n",
      "| 0.16944444444444445|\n",
      "|  0.5566666666666666|\n",
      "| 0.13361111111111112|\n",
      "|0.050833333333333335|\n",
      "|  0.6613888888888889|\n",
      "|  0.1688888888888889|\n",
      "|0.001944444444444...|\n",
      "| 0.12861111111111112|\n",
      "|              0.1575|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trip = df \\\n",
    "    .withColumn('trip_duration', (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 3600) \\\n",
    "    .select('trip_duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad4055bd-7b63-4d02-8b04-7ec56e7f39d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(trip_duration=162.61777777777777)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trip = df \\\n",
    "    .withColumn('trip_duration', (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 3600) \\\n",
    "    .select('trip_duration') \\\n",
    "    .orderBy(col('trip_duration').desc()) \\\n",
    "    .first()\n",
    "df_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5fd3962-9e11-44b9-a508-ede0f96c13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('LocationID', types.IntegerType(), True),\n",
    "    types.StructField('Borough', types.StringType(), True),\n",
    "    types.StructField('Zone', types.StringType(), True),\n",
    "    types.StructField('service_zone', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8471996d-5e93-47c6-bebd-f1d185f4f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('taxi_zone_lookup.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce78e537-900e-4060-bac0-6a30712be92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.createOrReplaceTempView('zones')\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c107bd32-e470-428b-af89-045c80baa86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:=============================>                            (2 + 2) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                Zone|zone_count|\n",
      "+--------------------+----------+\n",
      "|Governor's Island...|         1|\n",
      "|       Rikers Island|         2|\n",
      "|       Arden Heights|         2|\n",
      "| Green-Wood Cemetery|         3|\n",
      "|         Jamaica Bay|         3|\n",
      "|Charleston/Totten...|         4|\n",
      "|   Rossville/Woodrow|         4|\n",
      "|       West Brighton|         4|\n",
      "|       Port Richmond|         4|\n",
      "|Eltingville/Annad...|         4|\n",
      "|         Great Kills|         6|\n",
      "|        Crotona Park|         6|\n",
      "|Heartland Village...|         7|\n",
      "|     Mariners Harbor|         7|\n",
      "|Saint George/New ...|         9|\n",
      "|             Oakwood|         9|\n",
      "|       Broad Channel|        10|\n",
      "|New Dorp/Midland ...|        10|\n",
      "|         Westerleigh|        12|\n",
      "|     Pelham Bay Park|        12|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "with df_zones as (\n",
    "    select * \n",
    "    from df\n",
    "    inner join zones on df.PULocationID = zones.LocationID)\n",
    "select \n",
    "    df_zones.Zone,\n",
    "    count(*) as zone_count\n",
    "from df_zones\n",
    "group by df_zones.Zone\n",
    "order by zone_count\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
